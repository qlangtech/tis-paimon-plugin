## batchSize

在 Paimon 的 Stream 写入模式下，选择最佳的单次 Commit 记录数量需要平衡 **数据延迟**、**写入效率**和**小文件问题**三大因素。

⚠️ **必须规避的陷阱**
1. **过度追求低延迟**
   ```properties
   # 错误配置（导致小文件爆炸）
   commit.interval = 1s
   sink.buffer-size = 100
   ```
   **后果**：每秒生成数百小文件，NameNode 压力激增

2. **盲目增大批次**
   ```properties
   # 错误配置（内存溢出风险）
   sink.buffer-size = 1000000
   execution.checkpointing.interval = 10min
   ```
   **后果**：Flink TM OOM，Checkpoint 超时失败

3. **忽略数据特征**
    - **大对象场景**（如图片/文档）：
      ```properties
      # 改用数据体积控制
      sink.buffer-size = -1  # 禁用条数控制
      sink.max-buffer-size = 128mb  # 按体积Commit
      ```

📊 性能优化对照表
| **单Commit条数** | 延迟         | 吞吐       | 小文件风险 | 适用场景              |
|------------------|-------------|-----------|-----------|---------------------|
| <1,000           | 极低(1s内)  | 低        | 极高      | 实时监控告警         |
| 1,000~10,000     | 低(1~5s)    | 中等      | 高        | 实时报表/风控        |
| 10,000~50,000    | 中等(5~15s) | 高        | 中        | 通用CDC同步 ✅       |
| 50,000~200,000   | 较高(15~60s)| 极高      | 低        | 历史数据回填         |
| >200,000         | 高(>1min)   | 超高性能  | 极低      | 批量ETL(非实时)     |

**终极建议**：从 **25,000条/Commit** 开始（约5-10秒数据量），结合实时监控逐步调整。在精确控制延迟的场景，优先使用 `commit.interval` 时间阈值；在高吞吐场景，优先用 `sink.buffer-size` 条数控制，并始终开启自动合并防御小文件问题。