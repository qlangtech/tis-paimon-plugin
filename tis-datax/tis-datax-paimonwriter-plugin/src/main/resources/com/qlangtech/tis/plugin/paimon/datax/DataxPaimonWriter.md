## compaction

Apache Paimon 的 Compaction（压缩）机制是其核心功能之一，尤其在基于 LSM-Tree（Log-Structured Merge-Tree）架构的表格式中至关重要。它主要负责解决由频繁数据写入（尤其是流式写入）带来的小文件问题、读放大问题，并优化数据组织以提升查询性能。

Apache Paimon 的 Compaction 机制是其保证高性能、低延迟查询，尤其是处理高频更新/删除和流式写入场景的基石。它通过智能地合并小文件、清理过期数据、按主键排序数据，有效解决了 LSM-Tree 架构带来的挑战。Universal Compaction 策略因其对流式写入的友好性和易用性，成为 Paimon 的默认和推荐选项。理解并合理配置 Compaction 策略和参数，对于在生产环境中高效稳定地使用 Paimon 至关重要。

## snapshot

Apache Paimon 的 Snapshot（快照）机制 是其实现多版本并发控制（MVCC）、时间旅行查询（Time Travel）、增量计算和数据一致性的核心基础。它借鉴了 Iceberg 等现代数据表格式的设计思想，为存储在 Paimon 表中的数据提供了原子性、一致性、隔离性和持久性（ACID）的保证，特别适用于流批一体和实时更新的场景。

## paimonWriteMode

Paimon 的写入模式（`write-mode`）是影响数据写入行为的关键配置，`batch` 和 `stream` 两种模式在底层实现、数据可见性和适用场景上有本质区别：

🔄 **核心区别对比**
| **特性**               | **Batch 模式**                     | **Stream 模式**                   |
|------------------------|-----------------------------------|----------------------------------|
| **设计目标**           | 高吞吐批量处理                    | 低延迟实时处理                   |
| **数据可见性**         | 批次完成后可见                    | **实时可见**                     |
| **提交机制**           | 显式提交（如 Flink Checkpoint）   | 自动增量提交                     |
| **文件生成**           | 大文件（MB-GB级）                 | 小文件（KB-MB级）                |
| **写入延迟**           | 秒级~分钟级                       | **毫秒级~秒级**                  |
| **典型数据源**         | Hive/离线数仓                     | Kafka/CDC 流                    |
| **压缩效率**           | 高（大文件易压缩）                | 低（需额外小文件合并）           |
| **元数据开销**         | 低（单个提交点）                  | 高（频繁生成提交点）             |
| **Exactly-Once 保证**  | 依赖批处理框架                    | **原生支持**                     |

🚀 **适用场景**
 ✅ **Batch 模式最佳场景**
1. **离线数仓同步**
    - 每日全量同步 Hive 表：`write-mode=batch`
2. **大规模历史数据回填**
    - 初始化 TB 级历史数据
3. **资源敏感型环境**
    - 机械硬盘集群（减少 IOPS 压力）
4. **OLAP 分析优化**


 ✅ **Stream 模式最佳场景**
1. **实时 CDC 管道**
2. **低延迟监控看板**
    - 实时订单看板（要求 5s 内可见）
3. **事件驱动型应用**
    - 用户行为实时分析（点击流处理）
4. **渐进式更新场景**


## changelog

`changelog-producer` 的作用
1. **核心功能**
   - **生成变更日志**：将底层存储文件的物理更新（如覆盖写入）**转换为逻辑变更事件**（`+I`/`-U`/`+U`/`-D`）。
   - **支持流式消费**：让 Flink 等引擎能像读 Kafka 一样**增量读取 Paimon 表的变更**（类似 `SELECT * FROM table /*+ OPTIONS('scan.mode'='incremental') */`）。

2. 为何需要它？
   - **湖仓痛点**：传统湖存储（如 Parquet）只存最终状态，缺少 **"行级变更记录"**，无法支持增量计算。
   - **流读需求**：Flink CDC 等场景需要实时捕获 `INSERT/UPDATE/DELETE` 事件。